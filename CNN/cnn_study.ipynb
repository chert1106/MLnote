{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 莫烦Python tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From c:\\users\\zydar\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From c:\\users\\zydar\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\zydar\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\zydar\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001              # learning rate\n",
    "\n",
    "mnist = input_data.read_data_sets('./data', one_hot=True)  # they has been normalized to range (0,1)\n",
    "test_x = mnist.test.images[:2000]\n",
    "test_y = mnist.test.labels[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one example\n",
    "print(mnist.train.images.shape)     # (55000, 28 * 28)\n",
    "print(mnist.train.labels.shape)   # (55000, 10)\n",
    "plt.imshow(mnist.train.images[0].reshape((28, 28)), cmap='gray')\n",
    "plt.title('%i' % np.argmax(mnist.train.labels[0])); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_x = tf.placeholder(tf.float32, [None, 28*28]) / 255.\n",
    "image = tf.reshape(tf_x, [-1, 28, 28, 1])              # (batch, height, width, channel)\n",
    "tf_y = tf.placeholder(tf.int32, [None, 10])            # input y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "conv1 = tf.layers.conv2d(   # shape (28, 28, 1)\n",
    "    inputs=image,\n",
    "    filters=16,\n",
    "    kernel_size=5,\n",
    "    strides=1,\n",
    "    padding='same',\n",
    "    activation=tf.nn.relu\n",
    ")           # -> (28, 28, 16)\n",
    "pool1 = tf.layers.max_pooling2d(\n",
    "    conv1,\n",
    "    pool_size=2,\n",
    "    strides=2,\n",
    ")           # -> (14, 14, 16)\n",
    "conv2 = tf.layers.conv2d(pool1, 32, 5, 1, 'same', activation=tf.nn.relu)    # -> (14, 14, 32)\n",
    "pool2 = tf.layers.max_pooling2d(conv2, 2, 2)    # -> (7, 7, 32)\n",
    "flat = tf.reshape(pool2, [-1, 7*7*32])          # -> (7*7*32, )\n",
    "output = tf.layers.dense(flat, 10)              # output layer\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=tf_y, logits=output)           # compute cost\n",
    "train_op = tf.train.AdamOptimizer(LR).minimize(loss)\n",
    "\n",
    "accuracy = tf.metrics.accuracy(          # return (acc, update_op), and create 2 local variables\n",
    "    labels=tf.argmax(tf_y, axis=1), predictions=tf.argmax(output, axis=1),)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()) # the local var is for accuracy_op\n",
    "sess.run(init_op)     # initialize var in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 | train loss: 2.3098 | test accuracy: 0.16\n",
      "Step: 50 | train loss: 0.5405 | test accuracy: 0.50\n",
      "Step: 100 | train loss: 0.2282 | test accuracy: 0.63\n",
      "Step: 150 | train loss: 0.2974 | test accuracy: 0.70\n",
      "Step: 200 | train loss: 0.3693 | test accuracy: 0.75\n",
      "Step: 250 | train loss: 0.0883 | test accuracy: 0.78\n",
      "Step: 300 | train loss: 0.0355 | test accuracy: 0.80\n",
      "Step: 350 | train loss: 0.0793 | test accuracy: 0.82\n",
      "Step: 400 | train loss: 0.0845 | test accuracy: 0.84\n",
      "Step: 450 | train loss: 0.0552 | test accuracy: 0.85\n",
      "Step: 500 | train loss: 0.1051 | test accuracy: 0.86\n",
      "Step: 550 | train loss: 0.0886 | test accuracy: 0.87\n",
      "Step: 600 | train loss: 0.1830 | test accuracy: 0.87\n",
      "Step: 650 | train loss: 0.1230 | test accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "for step in range(700):\n",
    "    b_x, b_y = mnist.train.next_batch(BATCH_SIZE)\n",
    "    _, loss_ = sess.run([train_op, loss], {tf_x: b_x, tf_y: b_y})\n",
    "    if step % 50 == 0:\n",
    "        accuracy_, flat_representation = sess.run([accuracy, flat], {tf_x: test_x, tf_y: test_y})\n",
    "        print('Step:', step, '| train loss: %.4f' % loss_, '| test accuracy: %.2f' % accuracy_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 莫烦Python Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 38s 3us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()  # 加载mnist数据，路径C:\\Users\\zydar\\.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 1,28, 28)/255.\n",
    "X_test = X_test.reshape(-1, 1,28, 28)/255.\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to build your CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Conv layer 1 output shape (32, 28, 28)\n",
    "model.add(Convolution2D(\n",
    "    batch_input_shape=(None, 1, 28, 28),\n",
    "    filters=32,\n",
    "    kernel_size=5,\n",
    "    strides=1,\n",
    "    padding='same',     # Padding method\n",
    "    data_format='channels_first',\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling layer 1 (max pooling) output shape (32, 14, 14)\n",
    "model.add(MaxPooling2D(\n",
    "    pool_size=2,\n",
    "    strides=2,\n",
    "    padding='same',    # Padding method\n",
    "    data_format='channels_first',\n",
    "))\n",
    "\n",
    "# Conv layer 2 output shape (64, 14, 14)\n",
    "model.add(Convolution2D(64, 5, strides=1, padding='same', data_format='channels_first'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling layer 2 (max pooling) output shape (64, 7, 7)\n",
    "model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))\n",
    "\n",
    "# Fully connected layer 1 input shape (64 * 7 * 7) = (3136), output shape (1024)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Fully connected layer 2 to shape (10) for 10 classes\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Another way to define your optimizer\n",
    "adam = Adam(lr=1e-4)\n",
    "\n",
    "# We add metrics to get more results you want to see\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ------------\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 0.2704 - acc: 0.9261\n",
      "\n",
      "Testing ------------\n",
      "10000/10000 [==============================] - 1s 90us/step\n",
      "\n",
      "test loss:  0.10005062450654804\n",
      "\n",
      "test accuracy:  0.9687\n"
     ]
    }
   ],
   "source": [
    "print('Training ------------')\n",
    "# Another way to train the model\n",
    "model.fit(X_train, y_train, epochs=1, batch_size=64,)\n",
    "\n",
    "print('\\nTesting ------------')\n",
    "# Evaluate the model with the metrics we defined earlier\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Udacity](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/4_convolutions.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [百度狗细粒度分类比赛](https://github.com/ahangchen/keras-dogs/blob/master/README_cn.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [TensorFlow-Examples](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/convolutional_network.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
